{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net regression code\n",
    "\n",
    "* We begin with importing the necessary training data(metabolic fluxes & biomass).\n",
    "* Import the training data by typing the designated file name.\n",
    "\n",
    "| **Carbon** |    **acetate**   |  **adenosine**  | **D-alanine** |  **fructose**  |   **fucose**  |  **fumarate** | **galactose** | **galacturonate** | **gluconate** |      **glucosamine**     |\n",
    "|:----------:|:----------------:|:---------------:|:-------------:|:--------------:|:-------------:|:-------------:|:-------------:|:-----------------:|:-------------:|:------------------------:|\n",
    "|  file name |        ac        |       adn       |      alaD     |       fru      |      fuc      |      fum      |      gal      |       galur       |      glcn     |            gam           |\n",
    "| **Carbon** |    **glucose**   | **glucuronate** |  **glycerol** |   **lactate**  | **L-alanine** |   **malate**  |  **maltose**  |    **mannitol**   |  **mannose**  | **N-acetyl glucosamine** |\n",
    "|  file name |        glc       |      glcur      |      glyc     |       lac      |      alaL     |      mal      |      malt     |        mnl        |      man      |           acgam          |\n",
    "| **Carbon** | **oxaloacetate** |   **pyruvate**  |  **ribose**  | **saccharate** |  **sorbitol** | **succinate** | **thymidine** |   **trehalose**   |   **xylose**  |    **a-ketoglutarate**   |\n",
    "|  file name |        oaa       |       pyr       |      rib      |      sacc      |      sbt      |      succ     |     thymd     |        tre        |      xyl      |            akg           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_source = \"glc\" # glucose condition\n",
    "output_name = \"glc\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import package**\n",
    "\n",
    "For reproducibility, python & python packages' versions must be fixed as below.\n",
    "* python $\\;\\;\\;\\;$ : v. 3.6.5\n",
    "* H2O4GPU $\\;$ : v.  0.2.0\n",
    "* scikit-learn $\\;$ : v.  0.19.1\n",
    "* numpy  $\\;\\;\\;\\;$     : v. 1.19.5\n",
    "* pyarrow $\\;\\;\\;$ : v.  6.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python v. 3.6.5\n",
    "import sklearn # v. 0.19.1\n",
    "import pandas as pd # v. 1.1.5\n",
    "import numpy as np # v. 1.19.5\n",
    "from h2o4gpu.solvers.elastic_net import ElasticNet # v. 0.20.0\n",
    "from sklearn import preprocessing\n",
    "import h2o4gpu.util.import_data as io\n",
    "import h2o4gpu.util.metrics as metrics\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import data**\n",
    "\n",
    "* The simulated flux data is imported and preprocessed for training data (X_train).\n",
    "* We absolutized each flux values and filtered out those that had constant value across all deletion mutants.\n",
    "* The final 24 OD data from Tong(2020) and Baba(2006) were used as target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting metabolic flux data\n",
    "X_data_raw  = pd.read_feather(\"input_data/simulated_fluxes(\"+carbon_source+\").feather\").set_index(\"index\")\n",
    "\n",
    "#Remove any unnecessary columns(reactions)\n",
    "X_data = pd.DataFrame(index=X_data_raw.index)\n",
    "for index_col in X_data_raw.columns:\n",
    "    each_column = X_data_raw.loc[:, index_col]\n",
    "    not_constant = 0\n",
    "    if_forst = 0\n",
    "    for f_value in each_column:\n",
    "\n",
    "        if if_forst == 0:\n",
    "            default_value = f_value\n",
    "            if_forst = 1\n",
    "        elif f_value != default_value:\n",
    "            not_constant = 1\n",
    "\n",
    "    if not_constant == 0 and f_value ==0:\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        X_data[each_column.name] = abs(each_column)\n",
    "\n",
    "\n",
    "#Extracting growth data for target data\n",
    "growth_data = pd.read_feather(\"input_data/biomass_data.feather\").set_index(\"index\")\n",
    "y_data_raw =  growth_data[carbon_source]\n",
    "y_data = y_data_raw[y_data_raw.index.isin(X_data.index)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Machine learning with ElasticNet regression**\n",
    "Hyperparameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0 # random seed\n",
    "n_alphas    = 100 # number of alphas along the regularization path\n",
    "max_iter    = 1e4 # maximum number of iterations\n",
    "tol         = 1e-6 # tolerance for the optimization\n",
    "cv_folds    = 300 # number of cross validation folds\n",
    "l1_ratio    = 1e-2 # scaling between l1 and l2 penalties"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the machine learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize data\n",
    "X_train_scaled = sklearn.preprocessing.StandardScaler().fit_transform(X_data)\n",
    "\n",
    "#Shuffle the data\n",
    "y_train = y_data\n",
    "\n",
    "X_train_scaled, y_train = sklearn.utils.shuffle(X_train_scaled, y_train, random_state=random_seed)\n",
    "\n",
    "#Train the data\n",
    "enlr = ElasticNet(max_iter=max_iter,\n",
    "                  n_alphas=n_alphas,\n",
    "                  tol = tol,\n",
    "                  n_folds = cv_folds,\n",
    "                  l1_ratio = l1_ratio,\n",
    "                  random_state = random_seed\n",
    "                  )\n",
    "                  \n",
    "enlr.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract & filter the coefficients of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract each reaction's coefficient\n",
    "raw_coefs_data = pd.Series(enlr.coef_, index=X_data.columns , name=  \"Coefficient\").to_frame()\n",
    "\n",
    "#Filter out transport and external reactions\n",
    "memote_pure_rxn = open(\"util/memote_pure_rxns.txt\", 'r').read().strip('\"').split('\",\"')\n",
    "\n",
    "#Separate beneficial(+) and detrimental(-) reactions based on coefficient value\n",
    "coefs_pos = raw_coefs_data[raw_coefs_data.iloc[:, 0] > 0]\n",
    "coefs_neg = raw_coefs_data[raw_coefs_data.iloc[:, 0] < 0]\n",
    "\n",
    "#Filter out reactions with negligible coefficient value\n",
    "avg_coefs_pos = coefs_pos.iloc[:, 0].mean()\n",
    "avg_coefs_neg = coefs_neg.iloc[:, 0].mean()\n",
    "\n",
    "final_pos_coefs = coefs_pos[coefs_pos.iloc[:,0] >=  0.1*avg_coefs_pos]\n",
    "final_pos_coefs = final_pos_coefs[final_pos_coefs.index.isin(memote_pure_rxn) == True]\n",
    "final_neg_coefs = coefs_neg[abs(coefs_neg.iloc[:,0]) >= abs(0.1*avg_coefs_neg)]\n",
    "final_neg_coefs = final_neg_coefs[final_neg_coefs.index.isin(memote_pure_rxn) == True]\n",
    "\n",
    "#Sort and extract to csv\n",
    "filtered_coefs = final_pos_coefs.append(final_neg_coefs)\n",
    "filtered_coefs  = filtered_coefs.sort_values(ascending=False, by=\"Coefficient\") \n",
    "filtered_coefs.to_csv(\"EN_output_data/\"+output_name+\"_en_coefs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c257c458828b0801bd42c75066a4a4ab342d1b997385293a9445a5396be486a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
